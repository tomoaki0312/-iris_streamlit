# 必要なモジュールのインポート
import torch
import xml.etree.ElementTree as ET
from animal import transform, Net # animal.py から前処理とネットワークの定義を読み込み
#from flask import Flask, request, render_template, redirect
import io
from glob import glob
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from torchvision import transforms
import base64
import os

class Dataset(torch.utils.data.Dataset):
    def __init__(self, root, mode='train'):
        self.root = root
        self.mode = mode
        self.aerial_maritime_labels =  ['dennshinnbashira']
        self.transform = transforms.Compose([transforms.Resize((300, 300)), transforms.ToTensor()])
        self.data_list = sorted(glob(f'{root}\{mode}\*xml'))
    
    def __getitem__(self, idx):
        data = self.data_list[idx]
        parser = ET.parse(data)
        #parser = parse(data)
        img_path = parser.find('filename').text
        img_path = f'{self.root}\{self.mode}\{img_path}'
        img = Image.open(img_path)
        img = self.transform(img)
        target = []
        for obj in parser.findall('object'):
           bbox = obj.find('bndbox')
           xmin = 0
           ymin = 0
           xmax = 0
           ymax = 0
           name = obj.find('name').text
           label = int(self.aerial_maritime_labels.index(name))
           target.append([xmin, ymin, xmax, ymax, label])
        targets = torch.tensor(target, dtype=torch.float32)
        return img, targets
    def __len__(self):
        return len(self.data_list)
# データセットの取得
root = 'C:\data'
test = Dataset(root, mode='test')

from PIL import ImageDraw, ImageFont

def visualize_results(input, outputs, threshold):
  img= input.permute(1, 2, 0).numpy()
  image = Image.fromarray((img*255).astype(np.uint8))
  aerial_maritime_labels = ['test']
  scale = torch.Tensor(img.shape[1::-1]).repeat(2)
  draw = ImageDraw.Draw(image)
  font = ImageFont.truetype(r'C:\Users\t_nak\Desktop\animal_app\weights\NotoSansCJKjp-Bold.otf', 16)

  for i in range(outputs.size(1)):
    j = 0
    while outputs[0,i,j,0] >= threshold:
      score = outputs[0,i,j,0]
      label_name = aerial_maritime_labels[i-1]
      boxes = (outputs[0,i,j,1:]*scale).cpu().numpy()
      draw.rectangle(boxes, outline='red', width=5)
      #w, h = font.getsize(label_name)
      #w, h = draw.textsize(label_name, font=font)
      text_bbox = draw.textbbox((0, 0), label_name, font=font)
      #w, h = text_bbox.size
      w, h = text_bbox[2] - text_bbox[0], text_bbox[3] - text_bbox[1]
      draw.rectangle([boxes[0], boxes[1], boxes[0]+w, boxes[1]+h], fill='red')
      draw.text((boxes[0], boxes[1]), label_name, font=font, fill='white')
      j+=1
  return image

net = Net(phase='test', num_classes=6).cpu().eval()
# net.load_state_dict(torch.load('C:/Users/t_nak/Desktop/animal_app/src/ssd.pt'))
file_path = os.path.abspath('C:/Users/t_nak/Desktop/animal_app/src/ssd.pt')
net.load_state_dict(torch.load(file_path))

#checkpoint = torch.load(file_path)
#net.load_state_dict(checkpoint)

# test すべてに推論
plt.figure(figsize=(24, 12))
# net = Net(phase='test', num_classes=6).cpu().eval()
# net.load_state_dict(torch.load('ssd.pt', map_location=torch.device('cpu')))
for n in range(len(test)):
  x, t = test[n]
  y = net(x.unsqueeze(0))
  image = visualize_results(x, y, threshold=0.5)
  plt.subplot(4, 8, n+1)
  plt.imshow(image)
  plt.axis('off')
  plt.pause(0.001)  # 追加
plt.show()